{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4b6a674",
   "metadata": {},
   "source": [
    "# NFL Against the Spread Classification\n",
    "\n",
    "- Building a classification model to predict if an NFL team will beat, push, or lose to the spread\n",
    "- We will test multiple classification models and parameters to find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edd277fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, cohen_kappa_score, accuracy_score, roc_curve, auc\n",
    "\n",
    "# pipeline and grid search\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6001d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>season</th>\n",
       "      <th>team</th>\n",
       "      <th>opponent</th>\n",
       "      <th>spread_line</th>\n",
       "      <th>coach</th>\n",
       "      <th>roof</th>\n",
       "      <th>ats_win</th>\n",
       "      <th>location</th>\n",
       "      <th>epa</th>\n",
       "      <th>...</th>\n",
       "      <th>rush_yds_per_attempt</th>\n",
       "      <th>int</th>\n",
       "      <th>fumbles_lost</th>\n",
       "      <th>penalty_yards</th>\n",
       "      <th>def_epa</th>\n",
       "      <th>def_pass_yds_per_attempt</th>\n",
       "      <th>def_rush_yds_per_attempt</th>\n",
       "      <th>def_int</th>\n",
       "      <th>forced_fumbles</th>\n",
       "      <th>def_penlty_yards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001_01_CHI_BAL</td>\n",
       "      <td>2001</td>\n",
       "      <td>BAL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>10.5</td>\n",
       "      <td>Brian Billick</td>\n",
       "      <td>outdoors</td>\n",
       "      <td>win</td>\n",
       "      <td>home</td>\n",
       "      <td>-0.077838</td>\n",
       "      <td>...</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.247703</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001_01_NO_BUF</td>\n",
       "      <td>2001</td>\n",
       "      <td>BUF</td>\n",
       "      <td>NO</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>Gregg Williams</td>\n",
       "      <td>outdoors</td>\n",
       "      <td>lose</td>\n",
       "      <td>home</td>\n",
       "      <td>-0.340673</td>\n",
       "      <td>...</td>\n",
       "      <td>4.464286</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.040729</td>\n",
       "      <td>11.611111</td>\n",
       "      <td>4.192308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001_01_NE_CIN</td>\n",
       "      <td>2001</td>\n",
       "      <td>CIN</td>\n",
       "      <td>NE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dick LeBeau</td>\n",
       "      <td>outdoors</td>\n",
       "      <td>win</td>\n",
       "      <td>home</td>\n",
       "      <td>0.065117</td>\n",
       "      <td>...</td>\n",
       "      <td>4.757576</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>10.954545</td>\n",
       "      <td>3.238095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001_01_SEA_CLE</td>\n",
       "      <td>2001</td>\n",
       "      <td>CLE</td>\n",
       "      <td>SEA</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>Butch Davis</td>\n",
       "      <td>outdoors</td>\n",
       "      <td>win</td>\n",
       "      <td>home</td>\n",
       "      <td>-0.137322</td>\n",
       "      <td>...</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.118707</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>3.740741</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001_01_TB_DAL</td>\n",
       "      <td>2001</td>\n",
       "      <td>DAL</td>\n",
       "      <td>TB</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>Dave Campo</td>\n",
       "      <td>outdoors</td>\n",
       "      <td>win</td>\n",
       "      <td>home</td>\n",
       "      <td>-0.429948</td>\n",
       "      <td>...</td>\n",
       "      <td>4.304348</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.029573</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>2.151515</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           game_id  season team opponent  spread_line           coach  \\\n",
       "0  2001_01_CHI_BAL    2001  BAL      CHI         10.5   Brian Billick   \n",
       "1   2001_01_NO_BUF    2001  BUF       NO         -1.5  Gregg Williams   \n",
       "2   2001_01_NE_CIN    2001  CIN       NE          0.0     Dick LeBeau   \n",
       "3  2001_01_SEA_CLE    2001  CLE      SEA         -4.0     Butch Davis   \n",
       "4   2001_01_TB_DAL    2001  DAL       TB         -9.0      Dave Campo   \n",
       "\n",
       "       roof ats_win location       epa  ...  rush_yds_per_attempt  int  \\\n",
       "0  outdoors     win     home -0.077838  ...              1.800000    0   \n",
       "1  outdoors    lose     home -0.340673  ...              4.464286    3   \n",
       "2  outdoors     win     home  0.065117  ...              4.757576    0   \n",
       "3  outdoors     win     home -0.137322  ...              3.600000    1   \n",
       "4  outdoors     win     home -0.429948  ...              4.304348    2   \n",
       "\n",
       "   fumbles_lost  penalty_yards   def_epa  def_pass_yds_per_attempt  \\\n",
       "0             2             15 -0.247703                  5.750000   \n",
       "1             0             15  0.040729                 11.611111   \n",
       "2             1              0  0.004959                 10.954545   \n",
       "3             0              0 -0.118707                  8.900000   \n",
       "4             1             10 -0.029573                  7.800000   \n",
       "\n",
       "   def_rush_yds_per_attempt  def_int  forced_fumbles  def_penlty_yards  \n",
       "0                  2.000000        2               0                16  \n",
       "1                  4.192308        0               0                 0  \n",
       "2                  3.238095        0               0                 0  \n",
       "3                  3.740741        2               0                15  \n",
       "4                  2.151515        1               1                 0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in csv file\n",
    "\n",
    "df = pd.read_csv(\"../Data/nfl_game_data.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1daa20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns (game_id, team, )\n",
    "# convert season column from integer to category\n",
    "df[\"season\"] = df.season.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b64a218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10326 entries, 0 to 10325\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count  Dtype   \n",
      "---  ------                    --------------  -----   \n",
      " 0   season                    10326 non-null  category\n",
      " 1   opponent                  10326 non-null  object  \n",
      " 2   spread_line               10326 non-null  float64 \n",
      " 3   coach                     10326 non-null  object  \n",
      " 4   roof                      10326 non-null  object  \n",
      " 5   ats_win                   10326 non-null  object  \n",
      " 6   location                  10326 non-null  object  \n",
      " 7   epa                       10326 non-null  float64 \n",
      " 8   pass_yds_per_attempt      10326 non-null  float64 \n",
      " 9   rush_yds_per_attempt      10326 non-null  float64 \n",
      " 10  int                       10326 non-null  int64   \n",
      " 11  fumbles_lost              10326 non-null  int64   \n",
      " 12  penalty_yards             10326 non-null  int64   \n",
      " 13  def_epa                   10326 non-null  float64 \n",
      " 14  def_pass_yds_per_attempt  10326 non-null  float64 \n",
      " 15  def_rush_yds_per_attempt  10326 non-null  float64 \n",
      " 16  def_int                   10326 non-null  int64   \n",
      " 17  forced_fumbles            10326 non-null  int64   \n",
      " 18  def_penlty_yards          10326 non-null  int64   \n",
      "dtypes: category(1), float64(7), int64(6), object(5)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=[\"game_id\", \"team\"])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d0e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to use to run multiple models\n",
    "def test_model(model, data):\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    clf = model.fit(X_train, y_train)\n",
    "    prds = model.predict(X_test)\n",
    "#     print(f'Model: ')\n",
    "    print(f'Train score: {clf.score(X_train, y_train)}')\n",
    "    print(f\"-\"*40)\n",
    "    print(f'Test Score: {clf.score(X_test, y_test)}')\n",
    "    print(f\"-\"*40)\n",
    "    print(f\"Cohen's Kappa: {cohen_kappa_score(y_test, prds)}\")\n",
    "    print(f\"-\"*40)\n",
    "    print(f'''Confusion Matrix: \n",
    "{confusion_matrix(y_test, prds)}''')\n",
    "    print(f\"-\"*40)\n",
    "    print(f'''Classification Report:\n",
    "{classification_report(y_test, prds)}''')\n",
    "    plt.show()\n",
    "\n",
    "# split data into x and y \n",
    "\n",
    "X = df.drop(\"ats_win\", axis=1)\n",
    "y = df['ats_win']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)\n",
    "    \n",
    "data = [X_train, X_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdb04e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "numeric_features = [\"spread_line\", \"epa\", \"pass_yds_per_attempt\", \"rush_yds_per_attempt\", \"int\", \"fumbles_lost\", \\\n",
    "                    \"penalty_yards\", \"def_epa\", \"def_pass_yds_per_attempt\", \"def_rush_yds_per_attempt\", \"def_int\", \\\n",
    "                    \"forced_fumbles\", \"def_penlty_yards\"]\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_features = [\"season\", \"opponent\", \"coach\", \"roof\", \"location\"]\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d816002",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f7116cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.813918096292197\n",
      "----------------------------------------\n",
      "Test Score: 0.7989025177533893\n",
      "----------------------------------------\n",
      "Cohen's Kappa: 0.6081706915005058\n",
      "----------------------------------------\n",
      "Confusion Matrix: \n",
      "[[1265    0  267]\n",
      " [  44    0   39]\n",
      " [ 273    0 1210]]\n",
      "----------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.80      0.83      0.81      1532\n",
      "        push       0.00      0.00      0.00        83\n",
      "         win       0.80      0.82      0.81      1483\n",
      "\n",
      "    accuracy                           0.80      3098\n",
      "   macro avg       0.53      0.55      0.54      3098\n",
      "weighted avg       0.78      0.80      0.79      3098\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "log_regression_model = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression(max_iter=10000))])\n",
    "\n",
    "test_model(log_regression_model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91c4e92",
   "metadata": {},
   "source": [
    "### SGD Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c291259b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8123962368566685\n",
      "----------------------------------------\n",
      "Test Score: 0.7930923176242737\n",
      "----------------------------------------\n",
      "Cohen's Kappa: 0.5968239975458014\n",
      "----------------------------------------\n",
      "Confusion Matrix: \n",
      "[[1274    0  258]\n",
      " [  44    0   39]\n",
      " [ 299    1 1183]]\n",
      "----------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.79      0.83      0.81      1532\n",
      "        push       0.00      0.00      0.00        83\n",
      "         win       0.80      0.80      0.80      1483\n",
      "\n",
      "    accuracy                           0.79      3098\n",
      "   macro avg       0.53      0.54      0.54      3098\n",
      "weighted avg       0.77      0.79      0.78      3098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SGDC = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", SGDClassifier(max_iter=10000))])\n",
    "\n",
    "test_model(SGDC, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d4d0e",
   "metadata": {},
   "source": [
    "### KNeighbors Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e2f1d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8395130049806309\n",
      "----------------------------------------\n",
      "Test Score: 0.7646868947708199\n",
      "----------------------------------------\n",
      "Cohen's Kappa: 0.5427895956200608\n",
      "----------------------------------------\n",
      "Confusion Matrix: \n",
      "[[1245    4  283]\n",
      " [  46    0   37]\n",
      " [ 351    8 1124]]\n",
      "----------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.76      0.81      0.78      1532\n",
      "        push       0.00      0.00      0.00        83\n",
      "         win       0.78      0.76      0.77      1483\n",
      "\n",
      "    accuracy                           0.76      3098\n",
      "   macro avg       0.51      0.52      0.52      3098\n",
      "weighted avg       0.75      0.76      0.76      3098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kn = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", KNeighborsClassifier())])\n",
    "\n",
    "test_model(kn, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc88ab04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.686\n",
      "k: 3, Train/Test Score: 0.857/0.737\n",
      "k: 5, Train/Test Score: 0.840/0.765\n",
      "k: 7, Train/Test Score: 0.824/0.772\n",
      "k: 9, Train/Test Score: 0.819/0.769\n",
      "k: 11, Train/Test Score: 0.816/0.778\n",
      "k: 13, Train/Test Score: 0.814/0.784\n",
      "k: 15, Train/Test Score: 0.814/0.791\n",
      "k: 17, Train/Test Score: 0.813/0.792\n",
      "k: 19, Train/Test Score: 0.808/0.793\n",
      "k: 21, Train/Test Score: 0.806/0.794\n",
      "k: 23, Train/Test Score: 0.806/0.795\n",
      "k: 25, Train/Test Score: 0.809/0.796\n",
      "k: 27, Train/Test Score: 0.808/0.798\n",
      "k: 29, Train/Test Score: 0.807/0.796\n",
      "k: 31, Train/Test Score: 0.806/0.794\n",
      "k: 33, Train/Test Score: 0.805/0.795\n",
      "k: 35, Train/Test Score: 0.804/0.796\n",
      "k: 37, Train/Test Score: 0.803/0.794\n",
      "k: 39, Train/Test Score: 0.802/0.793\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through different k values to find which has the highest accuracy\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 40, 2):\n",
    "    knn = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", KNeighborsClassifier(n_neighbors=k))])\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_score = knn.score(X_train, y_train)\n",
    "    test_score = knn.score(X_test, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 40, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 40, 2), test_scores, marker=\"x\")\n",
    "loc, labels = plt.xticks()\n",
    "plt.xticks(np.arange(1, max(loc), step=2))\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ac04800",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8083840619811843\n",
      "----------------------------------------\n",
      "Test Score: 0.7979341510652034\n",
      "----------------------------------------\n",
      "Cohen's Kappa: 0.6061859342024117\n",
      "----------------------------------------\n",
      "Confusion Matrix: \n",
      "[[1277    0  255]\n",
      " [  42    0   41]\n",
      " [ 288    0 1195]]\n",
      "----------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.79      0.83      0.81      1532\n",
      "        push       0.00      0.00      0.00        83\n",
      "         win       0.80      0.81      0.80      1483\n",
      "\n",
      "    accuracy                           0.80      3098\n",
      "   macro avg       0.53      0.55      0.54      3098\n",
      "weighted avg       0.78      0.80      0.79      3098\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "kn = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", KNeighborsClassifier(n_neighbors = 27))])\n",
    "\n",
    "test_model(kn, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27092393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1277,    0,  255],\n",
       "       [  42,    0,   41],\n",
       "       [ 288,    0, 1195]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = kn.predict(X_test)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da2e426f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h2/k7j4q40n5gn2sjg57dg8x0pm0000gp/T/ipykernel_9235/2690595833.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \"\"\"\n\u001b[1;32m    770\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 771\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    534\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    535\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "y_pred_proba = kn.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd3d0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8803df41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbfedd6f",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e36035fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.0\n",
      "----------------------------------------\n",
      "Test Score: 0.7969657843770175\n",
      "----------------------------------------\n",
      "Cohen's Kappa: 0.6043380154829923\n",
      "----------------------------------------\n",
      "Confusion Matrix: \n",
      "[[1268    0  264]\n",
      " [  47    0   36]\n",
      " [ 282    0 1201]]\n",
      "----------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.79      0.83      0.81      1532\n",
      "        push       0.00      0.00      0.00        83\n",
      "         win       0.80      0.81      0.80      1483\n",
      "\n",
      "    accuracy                           0.80      3098\n",
      "   macro avg       0.53      0.55      0.54      3098\n",
      "weighted avg       0.78      0.80      0.79      3098\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", RandomForestClassifier())])\n",
    "\n",
    "test_model(rf, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbd596cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 22 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.3s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter classifer for estimator Pipeline(memory=None,\n         steps=[('preprocessor',\n                 ColumnTransformer(n_jobs=None, remainder='drop',\n                                   sparse_threshold=0.3,\n                                   transformer_weights=None,\n                                   transformers=[('num',\n                                                  Pipeline(memory=None,\n                                                           steps=[('imputer',\n                                                                   SimpleImputer(add_indicator=False,\n                                                                                 copy=True,\n                                                                                 fill_value=None,\n                                                                                 missing_values=nan,\n                                                                                 strategy='median',\n                                                                                 verbose=0)),\n                                                                  ('scaler',\n                                                                   StandardScaler(copy=True,\n                                                                                  with_mean...\n                                                   'def_penlty_yards']),\n                                                 ('cat',\n                                                  OneHotEncoder(categories='auto',\n                                                                drop=None,\n                                                                dtype=<class 'numpy.float64'>,\n                                                                handle_unknown='ignore',\n                                                                sparse=True),\n                                                  ['season', 'opponent',\n                                                   'coach', 'roof',\n                                                   'location'])],\n                                   verbose=False)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=5, p=2,\n                                      weights='uniform'))],\n         verbose=False). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n    for func, args, kwargs in self.items]\n  File \"/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 504, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/pipeline.py\", line 163, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\", line 50, in _set_params\n    super().set_params(**params)\n  File \"/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/base.py\", line 236, in set_params\n    (key, self))\nValueError: Invalid parameter classifer for estimator Pipeline(memory=None,\n         steps=[('preprocessor',\n                 ColumnTransformer(n_jobs=None, remainder='drop',\n                                   sparse_threshold=0.3,\n                                   transformer_weights=None,\n                                   transformers=[('num',\n                                                  Pipeline(memory=None,\n                                                           steps=[('imputer',\n                                                                   SimpleImputer(add_indicator=False,\n                                                                                 copy=True,\n                                                                                 fill_value=None,\n                                                                                 missing_values=nan,\n                                                                                 strategy='median',\n                                                                                 verbose=0)),\n                                                                  ('scaler',\n                                                                   StandardScaler(copy=True,\n                                                                                  with_mean...\n                                                   'def_penlty_yards']),\n                                                 ('cat',\n                                                  OneHotEncoder(categories='auto',\n                                                                drop=None,\n                                                                dtype=<class 'numpy.float64'>,\n                                                                handle_unknown='ignore',\n                                                                sparse=True),\n                                                  ['season', 'opponent',\n                                                   'coach', 'roof',\n                                                   'location'])],\n                                   verbose=False)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=5, p=2,\n                                      weights='uniform'))],\n         verbose=False). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h2/k7j4q40n5gn2sjg57dg8x0pm0000gp/T/ipykernel_9235/2515394149.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Fit on data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mbest_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter classifer for estimator Pipeline(memory=None,\n         steps=[('preprocessor',\n                 ColumnTransformer(n_jobs=None, remainder='drop',\n                                   sparse_threshold=0.3,\n                                   transformer_weights=None,\n                                   transformers=[('num',\n                                                  Pipeline(memory=None,\n                                                           steps=[('imputer',\n                                                                   SimpleImputer(add_indicator=False,\n                                                                                 copy=True,\n                                                                                 fill_value=None,\n                                                                                 missing_values=nan,\n                                                                                 strategy='median',\n                                                                                 verbose=0)),\n                                                                  ('scaler',\n                                                                   StandardScaler(copy=True,\n                                                                                  with_mean...\n                                                   'def_penlty_yards']),\n                                                 ('cat',\n                                                  OneHotEncoder(categories='auto',\n                                                                drop=None,\n                                                                dtype=<class 'numpy.float64'>,\n                                                                handle_unknown='ignore',\n                                                                sparse=True),\n                                                  ['season', 'opponent',\n                                                   'coach', 'roof',\n                                                   'location'])],\n                                   verbose=False)),\n                ('classifier',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=5, p=2,\n                                      weights='uniform'))],\n         verbose=False). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "# Define a grid of parameters to test in the model\n",
    "# Code adapted from Finn Qiao @ \n",
    "# https://towardsdatascience.com/logistic-regression-model-tuning-with-scikit-learn-part-1-425142e01af5\n",
    "\n",
    "# Create first pipeline for base without reducing features.\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression(max_iter = 10000)],\n",
    "     'classifier__penalty' : ['l1', 'l2']},\n",
    "    {'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10))}\n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(rf, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b6a310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_model(best_clf, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3311ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   16.7s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression(max_iter = 10000)],\n",
    "     'classifier__penalty' : ['l1', 'l2']},\n",
    "    {'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10))}\n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(log_regression_model, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbf1622b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   14.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.813918096292197\n",
      "----------------------------------------\n",
      "Test Score: 0.7989025177533893\n",
      "----------------------------------------\n",
      "Cohen's Kappa: 0.6081706915005058\n",
      "----------------------------------------\n",
      "Confusion Matrix: \n",
      "[[1265    0  267]\n",
      " [  44    0   39]\n",
      " [ 273    0 1210]]\n",
      "----------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.80      0.83      0.81      1532\n",
      "        push       0.00      0.00      0.00        83\n",
      "         win       0.80      0.82      0.81      1483\n",
      "\n",
      "    accuracy                           0.80      3098\n",
      "   macro avg       0.53      0.55      0.54      3098\n",
      "weighted avg       0.78      0.80      0.79      3098\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/larsonk/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "test_model(best_clf, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a9862ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score=nan,\n",
      "             estimator=Pipeline(memory=None,\n",
      "                                steps=[('preprocessor',\n",
      "                                        ColumnTransformer(n_jobs=None,\n",
      "                                                          remainder='drop',\n",
      "                                                          sparse_threshold=0.3,\n",
      "                                                          transformer_weights=None,\n",
      "                                                          transformers=[('num',\n",
      "                                                                         Pipeline(memory=None,\n",
      "                                                                                  steps=[('imputer',\n",
      "                                                                                          SimpleImputer(add_indicator=False,\n",
      "                                                                                                        copy=True,\n",
      "                                                                                                        fill_value=None,\n",
      "                                                                                                        missing_values=nan,\n",
      "                                                                                                        strategy='median',\n",
      "                                                                                                        verbose=0)),...\n",
      "                                                                min_impurity_decrease=0.0,\n",
      "                                                                min_impurity_split=None,\n",
      "                                                                min_samples_leaf=1,\n",
      "                                                                min_samples_split=2,\n",
      "                                                                min_weight_fraction_leaf=0.0,\n",
      "                                                                n_estimators=100,\n",
      "                                                                n_jobs=None,\n",
      "                                                                oob_score=False,\n",
      "                                                                random_state=None,\n",
      "                                                                verbose=0,\n",
      "                                                                warm_start=False)],\n",
      "                          'classifier__n_estimators': [10, 20, 30, 40, 50, 60,\n",
      "                                                       70, 80, 90, 100]}],\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "print(best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba82445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "528.844px",
    "left": "1534px",
    "right": "20px",
    "top": "170px",
    "width": "332px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
